{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thought Notebook\n",
    "New project, quick proof of concept notebook for artificial thought.\n",
    "\n",
    "Goal here is to turn audio transcriptions into focused summaries. Let's see if I can turn unstructured text into structured text without any added context or input parameters.\n",
    "\n",
    "THIS NOTEBOOK IN PARTICULAR: Is a concept for using LCEL to process text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "### 20240124:\n",
    "Working on learning to build chains with LangChain's LCEL. Want to take these to new level of complexity to allow for data processing, forks, parallel excution. \n",
    "\n",
    "What I want to show near term (for this dev notebook) is a linear serial flow of raw transcript to structured summary.\n",
    "\n",
    "1) pre-label -> clean up -> summary\n",
    "\n",
    "Then add complexity:\n",
    "2.1) pre-label -> clean up -> store\n",
    "2.2) pre-label -> clean up -> store\n",
    "2.3) retrieve (2.1 and 2.2) -> label -> summary\n",
    "\n",
    "REMEMBER THIS IS AN ART PROJECT THAT NEEDS TO BE FUN AND INTERESTING AND REQUIRE MINIMAL DEVELOPMENT EFFORT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    HumanMessagePromptTemplate,\n",
    "    PromptTemplate\n",
    ")\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser, CommaSeparatedListOutputParser, PydanticOutputParser, StringOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"\"\" \n",
    "    Your receive transcriptions of audio messages. Your job is to label the subject\n",
    "    of the message. You tag the message with multiple lables. You are both general and \n",
    "    specific. Your tags generally belong to a category, theme, or topic. \n",
    "\n",
    "    Messages could be about anything. Messages could be a boult multiple topics. In the \n",
    "    case of multiple topics tag with lables that fit the main topic. Ensure that a \n",
    "    general theme is tagged. All labels should have a general association with each other.\n",
    "    \n",
    "    It is likely that there are errors in the transcription, don't let that distract you.\n",
    "\n",
    "    -- EXAMPLE 1 --\n",
    "    Message: So I had this idea about a new app. The app will be a social media app that tracks\n",
    "    users across the platform to determine their interests. Profile information will be used to\n",
    "    present the user hyper-targeted ads.\n",
    "\n",
    "    Output: technology, social media, advertising, computer science, software development,\n",
    "    artificial intelligence, machine learning, data science, data analytics, data engineering\n",
    "\n",
    "    -- EXAMPLE 2 --\n",
    "    Message: I have a new idea for a business. I want to start a new business that sells a sweet\n",
    "    and tangy beverage. The beverage will be made from a fruit that is grown in the tropics called\n",
    "    lemon. Before starting the business I will need to create a financial model and marketing plan.\n",
    "\n",
    "    Output: business, entrepreneurship, finance, marketing, economics, accounting, management\n",
    "\n",
    "    FORMAT INSTRUCTIONS:\n",
    "    You must follow these instructions for formating output....\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "system_prompt = PromptTemplate(\n",
    "    template=role + \"\\n{format_instructions}\",\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "query = \"{transcription}\"\n",
    "\n",
    "prompt = ChatPromptTemplate(messages=[\n",
    "            SystemMessagePromptTemplate(prompt=system_prompt), \n",
    "            HumanMessagePromptTemplate.from_template(query)\n",
    "        ])\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "# model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "label_chain = prompt | model | output_parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CLEAN UP ########\n",
    "from operator import itemgetter\n",
    "# Prompt Template\n",
    "# ---------------\n",
    "class CleanUp():\n",
    "    def __init__(self):\n",
    "        role = \"\"\" \n",
    "            Your receive transcriptions of audio messages. It is likely that there are\n",
    "            errors in the transcription. Your job is to correct these errors. \n",
    "\n",
    "            You will do this by identifying the errors and correcting them. There is no \n",
    "            need to retype the entire message. You should simple output text that can \n",
    "            be used to identify the error and the correction.\n",
    "\n",
    "            You will be provided with labels that describe the content of the message generally.\n",
    "            Some labels will be more applicable than others. These labels should help you\n",
    "            identify the errors by providing context.\n",
    "\n",
    "            Acronyms and abbreviations are commonly transcribed incorrectly. The labels should \n",
    "            be very helpful in identifying these errors. If label is helpful and an acronym of \n",
    "            the raw transcription does not make sense, then use the label to correct the error.\n",
    "\n",
    "            REMINDER: Use minimal viable text to uniquely identify the error. Punctuation, grammar,\n",
    "            spelling, capitalization, and acronyms are all fair game.\n",
    "\n",
    "            -- EXAMPLE 1 --\n",
    "            Labels: shopping, produce, fruit, grocery store, supermarket, food, shopping list\n",
    "            Transcription: I went to the store early and bought fruit. Except I forgot to \n",
    "            buy orangutans.\n",
    "\n",
    "            Error: Except I forgot to buy orangutans.\n",
    "\n",
    "            Correction: Except I forgot to buy oranges.\n",
    "\n",
    "            -- EXAMPLE 2 --\n",
    "            Labels: technology, social media, advertising, computer science, software development\n",
    "            Transcription: So I had this idea about a new app. The app will be a social media app\n",
    "            that tracks users across the platform to determine their interests. The app will utilize\n",
    "            a new type of AI model called LOLms that can be used to interpret users posts. I will use\n",
    "            one from a company called OpenAI called GBTT-4.\n",
    "\n",
    "            Error: AI model called LOLms\n",
    "\n",
    "            Correction: AI model called LLMs\n",
    "\n",
    "            Error: OpenAI called GBTT-4\n",
    "\n",
    "            Correction: OpenAI called GPT-4\n",
    "\n",
    "            FOLLOW OUTPUT INSTRUCTIONS CAREFULLY\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Define a custom Pydantic model for error correction pairs\n",
    "        class ErrorCorrectionPair(BaseModel):\n",
    "            error: str = Field(description=\"The incorrect part of the transcription\")\n",
    "            correction: str = Field(description=\"The corrected part of the transcription\")\n",
    "\n",
    "        class ErrorCorrectionContainer(BaseModel):\n",
    "            error_correction_pairs: List[ErrorCorrectionPair] = Field(description=\"A list of error correction pairs\")\n",
    "\n",
    "        # Define a PydanticOutputParser with the custom Pydantic model\n",
    "        correction_parser = PydanticOutputParser(pydantic_object=ErrorCorrectionContainer)\n",
    "\n",
    "        query = \"Labels: {labels}\\n Transcription: {transcription}\"\n",
    "\n",
    "        system_prompt = PromptTemplate(\n",
    "            template=role + \"\\n{format_instructions}\",\n",
    "            input_variables=[],\n",
    "            partial_variables={\"format_instructions\": correction_parser.get_format_instructions()}\n",
    "        )\n",
    "\n",
    "        prompt = ChatPromptTemplate(messages=[\n",
    "                    SystemMessagePromptTemplate(prompt=system_prompt), \n",
    "                    HumanMessagePromptTemplate.from_template(query)\n",
    "                ])\n",
    "\n",
    "\n",
    "        model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "        # model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "        # Update the correction_chain to include the parser\n",
    "        self.chain = (\n",
    "            {\n",
    "            'transcription' : itemgetter('transcription'),\n",
    "            'labels' : itemgetter('labels'),\n",
    "            'error_correction_pairs' : prompt | model | correction_parser\n",
    "            }\n",
    "            | RunnableLambda(self.apply_corrections)\n",
    "        )\n",
    "\n",
    "    # Define the apply_corrections method inside the CleanUp class\n",
    "    @staticmethod\n",
    "    def apply_corrections(input_dict):\n",
    "        # from pprint import pprint\n",
    "        # pprint(input_dict)\n",
    "        transcription = input_dict['transcription']\n",
    "        error_correction_pairs = input_dict['error_correction_pairs'].error_correction_pairs\n",
    "        for pair in error_correction_pairs:\n",
    "            transcription = transcription.replace(pair.error, pair.correction)\n",
    "\n",
    "        output_dict = input_dict\n",
    "        output_dict['transcription'] = transcription\n",
    "        return output_dict\n",
    "        \n",
    "    def invoke(self, input_dict):\n",
    "        return self.chain.invoke(input_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prompt Template\n",
    "# ---------------\n",
    "role = \"\"\" \n",
    "    You have mastery of the English language. You specialize in helping writers and speakers better\n",
    "    communicate there ideas. You are a professional editor. You are a master of grammar and spelling.\n",
    "    \n",
    "    Your receive transcriptions of audio messages. You will be provided with labels that describe the\n",
    "    audio message. These labels should make sense in the context of the message. \n",
    "    \n",
    "    Your job is to summarize the transcription. You should summarize the message in context to one\n",
    "    or more of the labels. The summary should be contain all important details of the original message.\n",
    "    However, the summary should be concise. Please keep the summary to be the same length or shorter\n",
    "    than the original message.\n",
    "\n",
    "    Keep in mind that the transcription may not be concise or struggle to properly articulate idea. This\n",
    "    is the crux of you task. Interpret the messages intent without introducing new ideas. Interpret and \n",
    "    concolidate.\n",
    "\n",
    "\"\"\"\n",
    "query = \"Labels: {labels}\\n Transcription: {transcription}\"\n",
    "\n",
    "prompt = ChatPromptTemplate(messages=[\n",
    "            SystemMessagePromptTemplate.from_template(role),\n",
    "            HumanMessagePromptTemplate.from_template(query)\n",
    "        ])\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "final_chain = prompt | model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Execute Chain --    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# load a yaml file\n",
    "with open('thought.yaml') as file:\n",
    "    thought_file = yaml.load(file, Loader=yaml.FullLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['technology', 'artificial intelligence', 'machine learning', 'data processing', 'language processing', 'automation', 'summarization', 'information extraction', 'audio-to-text conversion', 'natural language processing']\n"
     ]
    }
   ],
   "source": [
    "transcription = \"\"\"\n",
    "OK, so I had this idea where I can take audio to text and store inside a AI brain that will process the text and turn it into more concise summarizations. The idea really stems out of the inability to concisely accurately and effectively describe plants and intention when recording audio off the cuff. For example, this sort of ramble here is a attempted articulation at a more sophisticated idea. it can potentially generally get a point across but will never contain all of the necessary items to complete set project or task contradictory statements. Any who the idea here is to have the LLMBA chain of multiple LM models with specific prompts for handling with The large rambles that come in in firstly, raw audio to text then it will be the LOM, responsibilities to first correct most basic errors, then perform summaries, and then extract useful information. It will also be the LLM or the AI discretion to extract certain concepts. This is going to be a majority automated process, wish more of potentially an art project than an affective tool however, if properly interesting useful results could come out. \n",
    "\"\"\"\n",
    "\n",
    "# print(label_chain.invoke({\"transcription\": transcription}).content)\n",
    "labels = label_chain.invoke({\"transcription\": transcription})\n",
    "print(f'Labels: {labels}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thought_0': 'OK, so I had this idea where I can take audio to text and store inside a AI brain that will process the text and turn it into more concise summarizations. The idea really stems out of the inability to concisely accurately and effectively describe plants and intention when recording audio off the cuff. For example, this sort of ramble here is a attempted articulation at a more sophisticated idea. it can potentially generally get a point across but will never contain all of the necessary items to complete set project or task contradictory statements. Any who the idea here is to have the LLMBA chain of multiple LM models with specific prompts for handling with The large rambles that come in in firstly, raw audio to text then it will be the LOM, responsibilities to first correct most basic errors, then perform summaries, and then extract useful information. It will also be the LLM or the AI discretion to extract certain concepts. This is going to be a majority automated process, wish more of potentially an art project than an affective tool however, if properly interesting useful results could come out. \\n', 'thought_1': 'So I have been thinking and now I am talking about a project where you store audio to text conversions. However, I’m not interested in the raw text from a more basic converter like Google speech, API or pockets. Thanks what I am interested in is for the project itself to be able to except clean and modify the raw inputs. Almost like creating a higher quality cleaned up labeled data set. The idea here is that the , larger looser dirtier data can be compressed down, so larger, loose semantics press down into articulate backed thoughts that can be presented to either the user or or or other people.\\n', 'thought_2': 'I think the project for storing ideas, and then displaying them in a consolidated improved format, first stemmed from another project idea, which was the consolidation of articles and news, and then have a sort of bot or AI. That is a journalist and can read and do research from previously publish material, and then use that material to produce a report .\\n', 'thought_3': 'One idea that I’ve been working with is the download of YouTube videos I’m more interested in videos that have content to them that service either classes or instruction. I’m especially interested in technical disciplines like science and math. What I’m doing with these download videos is extracting the subtitles or close caption text And storing them inside a vector database. Then a chat pot more common chat, like CBT for through the open AI website that sort of chat can query the database. If it feels like there is information that exist in it that is relevant to a conversation. So if, the user would like to talk about math and sort of think about the chat but as have watching a bunch of YouTube videos, was able to recall information on the spot and utilize it to assist the user in and chat dialogue.\\n', 'thought_4': 'Another idea is just a learning platform maybe or I guess I had aspirations that could be more but I called the project. Genesis Genesis was a sort of room or development space for chat, but I thought about it more as a room that you enter into have a conversation with one other individual, but certain individuals in the room might be better or more Signed to talk about specific subjects, easiest and most direct approach was just having the ability to select new system prompts for large language models before making API calls and putting in the framework is a chat button so be able to have a rolling memory behind the scenes, the project into the ability to deploy more complex code large language models used as AI agents so the ability to call functions. Currently have an implemented to crazy of a function really the only one that I use now consistently is a switch where someone is, taking the users role of selecting that system, prompt or the type of agent personality they want to be chatting with and instead there is a general point that can use discretion in order to pass the query onto the correct system prompt.', 'summary_0': 'Summary: The speaker proposes an AI model that converts audio into text, then processes it into concise summaries. This concept is born out of the difficulty in accurately describing plans and intentions when recording audio spontaneously. The proposal involves a chain of language models (LMs) tasked with correcting errors, summarizing content, and extracting useful information from verbose input. The process will be largely automated, with the AI given discretion to extract certain concepts. While primarily an artistic endeavor, it could yield useful results.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Invoke the chain with the labels and transcription\n",
    "c = CleanUp()\n",
    "# c.invoke({\"labels\": labels, \"transcription\": transcription})\n",
    "\n",
    "# big_chain = label_chain | c.chain\n",
    "big_chain = (\n",
    "    {\n",
    "        \"transcription\": itemgetter('transcription'), \n",
    "        \"labels\": label_chain\n",
    "    }\n",
    "    | c.chain\n",
    "    | final_chain\n",
    "\n",
    ")\n",
    "\n",
    "print(thought_file)\n",
    "\n",
    "output_file = thought_file.copy()\n",
    "for key, value in thought_file.items():\n",
    "    if 'thought' in key.lower():\n",
    "        summary = big_chain.invoke({\"transcription\": value}).content\n",
    "\n",
    "        output_key = key.replace('thought', 'summary')\n",
    "        output_file[output_key] = summary\n",
    "\n",
    "        # write to yaml file\n",
    "        with open('thought.yaml', 'w') as file:\n",
    "            yaml.dump(output_file, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
