{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Conner\\anaconda3\\envs\\athought\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mRegistering agent: PineconeAgent\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.base_agent import ChainableAgent, register_chain\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "from src.agents.agent_registry import register_agent\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "def create_debug_wrapper(name=\"\"):\n",
    "    def debug_wrapper(x):\n",
    "        print(f\"\\n--- Debug: {name} Input ---\")\n",
    "        print(json.dumps(x, indent=2, default=str))\n",
    "        return x  # Just pass through the input\n",
    "    return RunnableLambda(debug_wrapper)\n",
    "\n",
    "class PineconeAgent():\n",
    "    def __init__(self, title, **kwargs):\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.vector_store = PineconeVectorStore(index_name='langchain-test-index', embedding=self.embeddings)\n",
    "        self.retriever = self.vector_store.as_retriever()\n",
    "\n",
    "    def rag_chain(self):\n",
    "        rag_prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "        If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "        Use three sentences maximum and keep the answer as concise as possible.\n",
    "        {context}\n",
    "        Query: {query}\n",
    "        Helpful Answer:\"\"\"\n",
    "\n",
    "        rag_prompt = PromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "        def get_context(inputs):\n",
    "            query = inputs[\"query\"]\n",
    "            docs = self.retriever.invoke(query)\n",
    "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "        rag_chain = (\n",
    "            # RunnablePassthrough.assign(context=RunnableLambda(get_context), query=itemgetter('query'))\n",
    "            RunnablePassthrough.assign(context=RunnableLambda(get_context))\n",
    "            | create_debug_wrapper(\"Context and Query\")\n",
    "            | rag_prompt \n",
    "            | create_debug_wrapper(\"RAG Prompt\")\n",
    "            | ChatOpenAI(model='gpt-4o-2024-05-13')\n",
    "            | create_debug_wrapper(\"ChatBot Response\")\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        return rag_chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PineconeAgent(title='RAG Agent')\n",
    "rc = agent.rag_chain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Debug: Context and Query Input ---\n",
      "{\n",
      "  \"query\": \"Why is langchain so popular?\",\n",
      "  \"role\": \"You are a helpful assistant\",\n",
      "  \"context\": \"LangChain, which really helped it catch on. The platform formed a strong community on Discord,\\nwhere people continue to have lively discussions. In April 2023, LangChain attracted some big\\nventure capital investments for around $20 million. LangChain provides pre-built components\\ntailored for typical use cases, such as summarization, question & answer, and multi-agent bots.\\n\\u00a0\\u00a0\\u00a0\\u00a0\\u00a01.1.1 LangChain architecture\\n\\n1.1 Introducing LangChain\\n\\u00a0\\u00a0\\u00a0\\u00a0Since late 2022, several open-source LLM application frameworks have emerged. These frameworks\\no\\ufb00er ready-made components for common functions needed in developing LLM-powered\\napplications, saving developers time and e\\ufb00ort. They stay current with updates in data sources,\\nvector stores, and LLM advancements, thanks to collaboration from hundreds of developers. The\\nwidespread adoption of these frameworks helps establish best practices and patterns.\\n\\nand wider applicability than Semantic Kernel and Prompt Flow, which are mainly designed for\\nenterprise applications. Once you get familiar with LangChain, you'll likely be able to explore other\\nframeworks independently and choose the most suitable one for your speci\\ufb01c needs.\\n\\u00a0\\u00a0\\u00a0\\u00a0LangChain, kicked o\\ufb00 by Harrison Chase and Ankush Gola in October 2022 as an open-source\\nproject on Github, quickly became a hit. LLM enthusiasts started creating tutorial videos about\\n\\nallowed me to witness its rapid adoption within the community.\\n\\u00a0\\u00a0\\u00a0\\u00a0\\\"AI Applications with LangChain \\\" is structured to cater both to beginners and seasoned\\nprofessionals. It o\\ufb00ers a comprehensive look into the foundational technologies and advanced\\ntechniques in the realm of LLMs. Whether you are new to programming or an experienced\\ndeveloper, you will \\ufb01nd the content approachable yet enriching, especially with practical code\\nexamples to enhance your engagement.\"\n",
      "}\n",
      "\n",
      "--- Debug: RAG Prompt Input ---\n",
      "\"text='Use the following pieces of context to answer the question at the end. \\\\n        If you don\\\\'t know the answer, just say that you don\\\\'t know, don\\\\'t try to make up an answer.\\\\n        Use three sentences maximum and keep the answer as concise as possible.\\\\n        LangChain, which really helped it catch on. The platform formed a strong community on Discord,\\\\nwhere people continue to have lively discussions. In April 2023, LangChain attracted some big\\\\nventure capital investments for around $20 million. LangChain provides pre-built components\\\\ntailored for typical use cases, such as summarization, question & answer, and multi-agent bots.\\\\n\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\\xa01.1.1 LangChain architecture\\\\n\\\\n1.1 Introducing LangChain\\\\n\\\\xa0\\\\xa0\\\\xa0\\\\xa0Since late 2022, several open-source LLM application frameworks have emerged. These frameworks\\\\no\\ufb00er ready-made components for common functions needed in developing LLM-powered\\\\napplications, saving developers time and e\\ufb00ort. They stay current with updates in data sources,\\\\nvector stores, and LLM advancements, thanks to collaboration from hundreds of developers. The\\\\nwidespread adoption of these frameworks helps establish best practices and patterns.\\\\n\\\\nand wider applicability than Semantic Kernel and Prompt Flow, which are mainly designed for\\\\nenterprise applications. Once you get familiar with LangChain, you\\\\'ll likely be able to explore other\\\\nframeworks independently and choose the most suitable one for your speci\\ufb01c needs.\\\\n\\\\xa0\\\\xa0\\\\xa0\\\\xa0LangChain, kicked o\\ufb00 by Harrison Chase and Ankush Gola in October 2022 as an open-source\\\\nproject on Github, quickly became a hit. LLM enthusiasts started creating tutorial videos about\\\\n\\\\nallowed me to witness its rapid adoption within the community.\\\\n\\\\xa0\\\\xa0\\\\xa0\\\\xa0\\\"AI Applications with LangChain \\\" is structured to cater both to beginners and seasoned\\\\nprofessionals. It o\\ufb00ers a comprehensive look into the foundational technologies and advanced\\\\ntechniques in the realm of LLMs. Whether you are new to programming or an experienced\\\\ndeveloper, you will \\ufb01nd the content approachable yet enriching, especially with practical code\\\\nexamples to enhance your engagement.\\\\n        Query: Why is langchain so popular?\\\\n        Helpful Answer:'\"\n",
      "\n",
      "--- Debug: ChatBot Response Input ---\n",
      "\"content='LangChain is popular due to its pre-built components tailored for typical use cases, saving developers time and effort in creating LLM-powered applications. It has built a strong community on Discord, fostering lively discussions and collaboration. Additionally, significant venture capital investments and early support from LLM enthusiasts have boosted its visibility and adoption.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 445, 'total_tokens': 508, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_057232b607', 'finish_reason': 'stop', 'logprobs': None} id='run-7a76e9cf-aded-46d5-a6c7-3bae82e3f607-0' usage_metadata={'input_tokens': 445, 'output_tokens': 63, 'total_tokens': 508}\"\n"
     ]
    }
   ],
   "source": [
    "answer = rc.invoke({'query': 'Why is langchain so popular?', 'role': 'You are a helpful assistant'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The moon does not have a capital as it is not a governed entity.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athought",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
